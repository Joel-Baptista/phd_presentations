@article{Scalbert2021,
  author       = {Marin Scalbert and
                  Maria Vakalopoulou and
                  Florent Couzini{\'{e}}{-}Devy},
  title        = {Multi-Source domain adaptation via supervised contrastive learning
                  and confident consistency regularization},
  journal      = {CoRR},
  volume       = {abs/2106.16093},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.16093},
  eprinttype    = {arXiv},
  eprint       = {2106.16093},
  timestamp    = {Mon, 05 Jul 2021 15:15:50 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-16093.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{RATO2022497,
title = {A sensor-to-pattern calibration framework for multi-modal industrial collaborative cells},
journal = {Journal of Manufacturing Systems},
volume = {64},
pages = {497-507},
year = {2022},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2022.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0278612522001182},
author = {Daniela Rato and Miguel Oliveira and Vítor Santos and Manuel Gomes and Angel Sappa},
keywords = {Calibration, Collaborative cell, Multi-modal, Multi-sensor},
abstract = {Collaborative robotic industrial cells are workspaces where robots collaborate with 
human operators. In this context, safety is paramount, and for that a complete perception of the
space where the collaborative robot is inserted is necessary. To ensure this, collaborative 
cells are equipped with a large set of sensors of multiple modalities, covering the entire work volume.
However, the fusion of information from all these sensors requires an accurate extrinsic calibration. 
The calibration of such complex systems is challenging, due to the number of sensors and modalities, and
also due to the small overlapping fields of view between the sensors, which are positioned to capture different
viewpoints of the cell. This paper proposes a sensor to pattern methodology that can calibrate a complex system
such as a collaborative cell in a single optimization procedure. Our methodology can tackle RGB and Depth cameras,
as well as LiDARs. Results show that our methodology is able to accurately calibrate a collaborative cell containing
three RGB cameras, a depth camera and three 3D LiDARs.}
}

@article{s21124113,
author = {Castro, Afonso and Silva, Filipe and Santos, Vitor},
title = {Trends of Human-Robot Collaboration in Industry Contexts: Handover, Learning, and Metrics},
journal = {Sensors},
volume = {21},
year = {2021},
number = {12},
ARTICLE-NUMBER = {4113},
url = {https://www.mdpi.com/1424-8220/21/12/4113},
PubMedID = {34203766},
issn = {1424-8220},
abstract = {Repetitive industrial tasks can be easily performed by traditional robotic systems. 
However, many other works require cognitive knowledge that only humans can provide. 
Human-Robot Collaboration (HRC) emerges as an ideal concept of co-working between a human 
operator and a robot, representing one of the most significant subjects for human-life improvement.
The ultimate goal is to achieve physical interaction, where handing over an object plays a crucial 
role for an effective task accomplishment. Considerable research work had been developed in this 
particular field in recent years, where several solutions were already proposed. Nonetheless, some 
particular issues regarding Human-Robot Collaboration still hold an open path to truly important 
research improvements. This paper provides a literature overview, defining the HRC concept, 
enumerating the distinct human-robot communication channels, and discussing the physical 
interaction that this collaboration entails. Moreover, future challenges for a natural and 
intuitive collaboration are exposed: the machine must behave like a human especially in the 
pre-grasping/grasping phases and the handover procedure should be fluent and bidirectional, 
for an articulated function development. These are the focus of the near future investigation 
aiming to shed light on the complex combination of predictive and reactive control mechanisms 
promoting coordination and understanding. Following recent progress in artificial intelligence, 
learning exploration stand as the key element to allow the generation of coordinated actions and 
their shaping by experience.},
doi = {10.3390/s21124113}
}

@article{afonso2023,
title = {Classification of handover interaction primitives in a COBOT–human context with a deep neural network},
journal = {Journal of Manufacturing Systems},
volume = {68},
pages = {289-302},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523000614},
author = {Afonso Castro and Joel Baptista and Filipe Silva and Vitor Santos},
keywords = {Collaborative robotics, Physical HRI, Robot-to-human handover, Multiclass classification, Learning-based approach},
abstract = {Object handover between humans and robots is an extremely important concern and lays on the edge of 
human–robot interaction challenges. This paper proposes a new approach to classify physical human interactions 
with a COBOT for handover operations. The human actions are categorized in simple interaction primitives. 
A deep neural network was devised and trained to classify torques and forces measured on the robot into one 
of four interaction primitives, namely pull, push, shake and twist. More specifically, an input vector of 
forces and torques observed and accumulated during a short span of half a second is fed into a properly 
trained feedforward deep neural network that classifies the interaction as one of the four primitives established. 
A specific dataset was created using several persons that provided abundant data both for training and testing. 
The results are very good not only in the training phase demonstrated by the convergence indicators, but also 
in the testing phase where interactions from previously unseen operators were successfully classified with an 
outstanding confidence.
}
}

@article{DBLP:journals/corr/abs-2004-11362,
  author       = {Prannay Khosla and
                  Piotr Teterwak and
                  Chen Wang and
                  Aaron Sarna and
                  Yonglong Tian and
                  Phillip Isola and
                  Aaron Maschinot and
                  Ce Liu and
                  Dilip Krishnan},
  title        = {Supervised Contrastive Learning},
  journal      = {CoRR},
  volume       = {abs/2004.11362},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.11362},
  eprinttype    = {arXiv},
  eprint       = {2004.11362},
  timestamp    = {Wed, 28 Dec 2022 08:11:08 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-11362.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}